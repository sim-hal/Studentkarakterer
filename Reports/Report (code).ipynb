{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "junior-vessel",
   "metadata": {},
   "source": [
    "# Rapport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-tours",
   "metadata": {},
   "source": [
    "### Innledning\n",
    "\n",
    "I denne rapporten vurderer vi hvordan vi kan bruke Python og Pythons relevante maskinlærings-biblioteker til å lage maskinærings-modeller som predikerer elevers avgangskarakterer.\n",
    "\n",
    "Vi starter med å lese og tolke dataene. For enkelthets skyld, har vi valgt å bare bruke datasettet med elevenes portugisisk-karakterer, ikke datasettet med elevenes matte-karakterer. Vi valgte datasettet med portugisisk-karakterene fordi dette er størst. Videre forbereder vi dataene, før vi lager tre forskjellige modeller. Forskjellen mellom modellene er hvilke forklaringsvariabler de bruker. Til slutt sammenligner vi de tre modellene og plotter noen av egenskapene deres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arabic-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importering av relevante Python-bibliotek\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import LeaveOneOut, GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "import xgboost as xgb\n",
    "\n",
    "#Visningsinstillinger\n",
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-adapter",
   "metadata": {},
   "source": [
    "### Lesing og tolking av dataene\n",
    "\n",
    "Vi starter med å lese og tolke dataen. Vi ser at vi har 649 rader og 33 kolonner, altså har vi 649 elever og 33 variabler for hver elev. \"G3\" er avgangskarakteren vi vil predikere, mens de 32 andre variablene er forklaringsvariabler. \n",
    "\n",
    "Videre plotter vi variablene... Hvilke variabler og færre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "frank-spiritual",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2c6c4ce6abbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Leser og viser dataene\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"student-por.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Antall elever = {df_tmp.shape[0]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Antall variabler = {df_tmp.shape[1]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#Leser og viser dataene\n",
    "df_tmp = pd.read_csv(\"student-por.csv\")\n",
    "print(df_tmp.head())\n",
    "print(f\"Antall elever = {df_tmp.shape[0]}\")\n",
    "print(f\"Antall variabler = {df_tmp.shape[1]}\")\n",
    "\n",
    "#Plot\n",
    "#response = np.asarray(df_tmp[\"G3\"])\n",
    "\n",
    "numeric_plots = [\"age\", \"Medu\", \"Fedu\", \"traveltime\", \"studytime\", \"failures\", \"famrel\", \"goout\", \"Dalc\", \"Walc\", \"health\", \"absences\", \"G1\", \"G2\" ]\n",
    "for variable in numeric_plots:\n",
    "    df_tmp.plot(kind = \"scatter\", x = variable, y =\"G3\")\n",
    "\n",
    "categorical_plots=[\"sex\", \"school\", \"address\", \"Pstatus\", \"Mjob\", \"Fjob\", \"guardian\", \"famsize\", \"reason\", \"schoolsup\", \"famsup\", \"activities\", \"paid\", \"internet\", \"nursery\", \"higher\", \"romantic\"]\n",
    "for variable in categorical_plots:\n",
    "    df_tmp.boxplot(variable, \"G3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-filter",
   "metadata": {},
   "source": [
    "### Forberedelse av dataene\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-hughes",
   "metadata": {},
   "source": [
    "Videre forbereder vi dataene. Vi starter med å sjekke om vi mangler noe data. Det gjør vi ikke. Deretter bruker vi \"one hot encoding\" på de kategoriske variablene. Vi setter \"drop_first = True\", for å fjerne unødvendige \"dummy\"-variabler; vi vil ha en så enkel modell som mulig.  Vi splitter så variablene i forklaringsvariabler X og respons Y. Responsen Y er den samme for modell 1, modell 2 og modell 3, mens forklaringsvariablene varierer for de tre modellene. Vi lager derfor tre lister med forklaringsvariabler: X1, X2 og X3. Til slutt splitter vi X-ene og Y inn i treningssett og testsett. Vi har valgt at treningssettet skal bestå av 20% av det totale datasettet. Dermed består testsettet av 80% av det totale datasettet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "flush-copying",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sjekker om det vi mangler noe data\n",
    "df_tmp.isnull().sum()\n",
    "\n",
    "#Bruker \"one hot encoding\" på de kategoriske variablene\n",
    "categorical_cols=[\"sex\", \"school\", \"address\", \"Pstatus\", \"Mjob\", \"Fjob\", \"guardian\", \"famsize\", \"reason\", \"schoolsup\", \"famsup\", \"activities\", \"paid\", \"internet\", \"nursery\", \"higher\", \"romantic\"]\n",
    "df = pd.get_dummies(df_tmp, columns=categorical_cols, prefix=categorical_cols, prefix_sep=\"_\", drop_first = True)\n",
    "\n",
    "#Splitter forklaringsvariabler X og respons Y\n",
    "X1 = df.drop([\"G3\", ], axis=1)\n",
    "X2 = df[[\"G1\", \"G2\"]]\n",
    "X3 = df[[\"G1\", \"G2\", \"failures\", \"school_MS\"]]\n",
    "Y = df[\"G3\"]\n",
    "\n",
    "#Splitter treningssett og testsett\n",
    "X1_train, X1_test, X2_train, X2_test, X3_train, X3_test, Y_train, Y_test = train_test_split(X1, X2, X3, Y, test_size = 0.20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-concern",
   "metadata": {},
   "source": [
    "### Trening og testing\n",
    "\n",
    "Neste steg er å trene og teste modellene. I treningen og testingen av modellene bruker vi Python-biblioteket XGboost. XGboost lager en skog med boostede regresjonstrær, basert på forskjellige parametere. Vi har valgt å inkludere følgende parametere: eta (læringsrate), max_depth (treets maksdybde), xxx\n",
    "Vi har valgt akkurat disse parametrene fordi... xxxx Vi bruker XGboost sine innebygde funksjoner for cross-validation til å lage modeller, på treningssettet, med alle mulige kombinasjoner av parametere. Vi velger ut modellen som gir best prediksjon. Hvilken modell som gir best prediksjon, bestemmes av XGboost sin \"best_estimator\"-funksjon. Til slutt bruker vi modellen på dataene i test-settet til å predikere karakterer, for så å sammenligne de predikerte karakterene med de gitte karakterene i testsettet. For å sammenligne bruker vi gjennomsnittlig kvadrert feil, MSE.\n",
    "\n",
    "For oversikts skyld, går vi videre gjennom treningen og testingen av én og én modell. \n",
    "\n",
    "#### Model 1\n",
    "Modell 1 bruker alle variablene som forklaringsvariabler. Her ser vi at kombinasjonen av eta = x, max_depth = x, ...xxx gir den beste modellen. Når vi tester denne modellen får vi en MSE på xxx.\n",
    "\n",
    "\n",
    "#### Model 2\n",
    "Modell 2 bruker elevenes tidligere karakterer som forklaringsvariabler. Her ser vi at kombinasjonen av eta = x, max_depth = x, ...xxx gir den beste modelln. Når vi teser denne modellen får vi en MSE på xxx.\n",
    "\n",
    "#### Model 3\n",
    "Modell 2 bruker elevenes tidligere karakterer, stryk og skoler som forklaringsvariabler. Disse variablene har vi valgt ut, fordi vi anser de som juridisk og etisk rettferdige å bruke. For flere detaljer, se den andre rapporten. Her ser vi at kombinasjonen av eta = x, max_depth = x, ...xxx gir den beste modelln. Når vi teser denne modellen får vi en MSE på xxx.\n",
    "\n",
    "\n",
    "#### Sammenligning\n",
    "Når vi sammenligner de tre modellene, ser vi altså at modell x er den beste, y er den nest beste og z er den dårligste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setter parametere og modell\n",
    "params = {\"eta\": [0.01, 0.02, 0.1, 0.15, 0.2, 0.3], \"max_depth\": [1, 2, 3, 4, 5], \"tree_method\": [\"auto\", \"exact\", \"approx\", \"hist\"], }\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "GsCV = GridSearchCV(xgb_model, params, verbose=0, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "#Model 1\n",
    "GsCV.fit(X1_train, Y_train)     #Lager modeller med forskjellige kombinasjoner av parametere\n",
    "model1 = GsCV.best_estimator_   #Den beste modellen\n",
    "print(GsCV.best_score_)         #Negative MSE for den beste modellen\n",
    "print(GsCV.best_params_)        #Kombinasjonen av parametere i den beste modellen\n",
    "prediction1 = model1.predict(X1_test)\n",
    "print(model1.score(X1_test, Y_test))\n",
    "\n",
    "#Model 2\n",
    "GsCV.fit(X2_train, Y_train)      #Lager modeller med forskjellige kombinasjoner av parametere\n",
    "model2 = GsCV.best_estimator_    #Den beste modellen\n",
    "print(GsCV.best_score_)          #Negative MSE for den beste modellen\n",
    "print(GsCV.best_params_)         #Kombinasjonen av parametere i den beste modellen\n",
    "prediction2 = model2.predict(X2_test)\n",
    "print(model2.score(X2_test, Y_test))\n",
    "\n",
    "#Model 3\n",
    "GsCV.fit(X3_train, Y_train)       #Lager modeller med forskjellige kombinasjoner av parametere\n",
    "model3 = GsCV.best_estimator_     #Den beste modellen\n",
    "print(GsCV.best_score_)           #Negative MSE for den beste modellen\n",
    "print(GsCV.best_params_)          #Kombinasjonen av parametere i den beste modellen\n",
    "prediction_3 = model3.predict(X3_test)\n",
    "print(model3.score(X3_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-mississippi",
   "metadata": {},
   "source": [
    "### Plot\n",
    "\n",
    "Til slutt vil vi plotte viktigheten av de forskjellige forklaringsvariablene og avhengighetene til modellene. Vi ser samtidig på hvordan det påvirker elevenes karakterer å fjerne eller endre noen av forklaringsvariablene. \n",
    "\n",
    "Vi starter med å plotte viktigheten av de forskjellige forklaringsvariablene for de tre modellene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotter viktigheten av forklaringsvariablene\n",
    "\n",
    "#Modell 1\n",
    "model1_features = model1.feature_importances_\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(model1_features)\n",
    "\n",
    "#Modell 2\n",
    "model2_features = model1.feature_importances_\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(model2_features)\n",
    "\n",
    "#Modell 3\n",
    "model3_features = model1.feature_importances_\n",
    "plt.subplot(1,3,3)\n",
    "bins = np.linspace(0, 2, 40)\n",
    "plt.hist(model3_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-sigma",
   "metadata": {},
   "source": [
    "Vi plotter så avhengigheten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "confused-fundamental",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-76761a10704a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Modell 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_partial_dependence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_1_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_1_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Modell 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot_partial_dependence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_2_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_2_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "#Plotter avhengigheten\n",
    "\n",
    "#Modell 1\n",
    "#plot_partial_dependence(model1, X1_test, X1_test.columns.values)\n",
    "\n",
    "#Modell 2\n",
    "#plot_partial_dependence(model2, X2_test, X2.columns.values)\n",
    "\n",
    "#Modell 3\n",
    "#plot_partial_dependence(model3, X3_test, X3_test.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-whale",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-ethnic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
